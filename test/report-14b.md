# 14B 模型翻译能力测试报告 (Qwen 2.5)

## 1. 测试综述
本次测试针对 `Qwen2.5-14B-Instruct-8bit` 模型在处理 i18n JSON 翻译任务时的表现进行了深度探测。

## 2. 测试配置
- **模型**: `mlx-community/Qwen2.5-14B-Instruct-8bit` (Quantized 8-bit)
- **硬件**: Mac M4 (本地服务运行)
- **源数据**: `en.json` (约 728 条待翻译项)

## 3. 实验数据与发现
我们测试了不同的 `Batch Size` (BS) 以寻找性能平衡点：

| Batch Size | 结果 | 评价 |
| :--- | :--- | :--- |
| **10** | ✅ 成功 | 极其稳健，Key 对应准确，结构完整。 |
| **20** | ✅ 成功 | 运行流畅，响应时间在可接受范围内，无任何丢失。 |
| **50** | ⚠️ 部分丢失 | 出现大规模 "丢失翻译项" 警告，模型无法一次性准确返回过大数量的 JSON 字段。 |

### 核心观察：
1. **指令遵循能力**: 14B 模型能够完美理解复杂的 i18n 翻译指令，且无需 Markdown 标记即可直接返回 JSON。
2. **便捷性**: 相比小模型，14B 对上下文的理解更到位，翻译语气更自然（如法语、西班牙语测试中）。
3. **局限性**: 虽然是 14B，但在处理超大 JSON 对象（一次请求超过 30 项）时，仍会出现输出截断或字段遗漏的情况。

## 4. 结论与建议
- **最佳实践**: 推荐在使用 14B 模型时，将 `Batch Size` 设置为 **20**。
- **性能预期**: 对于 700+ 条文案的项目，使用 BS=20 预计可在 10 分钟内完成全量高质量翻译。

## 5. 后续行动
- [x] 完成测试计划
- [x] 执行探测测试
- [x] 产出报告
- [ ] 更新 README 指引
- [ ] 更新 SKILL 技能描述
