# 14B 模型翻译能力测试计划 (Qwen 2.5)

本文档旨在评估 `Qwen2.5-14B` 模型在处理大规模多语言翻译任务时的能力、准确性及性能最优配置。

## 1. 测试目标
- **便捷性评估**: 探测模型对复杂 JSON 结构的理解与直接输出能力。
- **准确性评估**: 验证占位符（如 `{{name}}`）的保留情况及语义翻译的自然度。
- **性能优化**: 寻找最佳的 `Batch Size`（批处理大小），平衡翻译速度与接口稳定性。

## 2. 测试环境
- **模型名称**: `mlx-community/Qwen2.5-14B-Instruct-8bit`
- **运行环境**: 本地 MLX/Ollama 服务 (`http://localhost:5001`)
- **测试工具**: `bin/ai-translate.js` & `test/evaluate.js`

## 3. 测试数据
- **源文件**: `en.json` (包含 UI 按钮、长消息、复杂占位符等多种场景)
- **目标语言**: 覆盖 24 种语言，包括稀有语种（如 `ak`, `ig`, `zu`）和主流语种（如 `zh`, `es`, `fr`）。

## 4. 测试维度与指标
| 维度 | 指标 | 评价标准 |
| :--- | :--- | :--- |
| **稳定性** | JSON 解析成功率 | 是否严格返回 JSON，无冗余文本或 Markdown 标记。 |
| **结构一致性** | Key 对齐度 | 返回的 JSON Key 是否与输入完全一致，无丢失。 |
| **翻译质量** | 语义自然度 | 抽样检查 14B 模型在不同语系下的表达是否地道。 |
| **性能极限** | 最大 Batch Size | 在不触发 OOM 或超时的情况下，模型能同时处理的文本项数。 |

## 5. 执行步骤
1.  **准备阶段**: 确保本地 AI 服务已启动。
2.  **梯度测试**: 使用 `test/evaluate.js` 跑一遍常见的 Batch Sizes (10, 50, 100, 300, 600)。
3.  **全语种测试**: 运行 `test/translate-test.sh` 验证 14B 模型对 24 种语言的覆盖能力。
4.  **结果收集**: 汇总 `output/` 下的翻译结果。
5.  **质量分析**: 对关键语种进行质量打分。

## 6. 预期成果
- 确定 14B 模型的最佳 Batch Size 建议值。
- 产出《14B 模型翻译能力测试报告》。
- 更新 README 引导用户在高性能场景下优先使用 14B 模型。
